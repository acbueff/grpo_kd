{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with TensorFlow on Alvis\n",
    "This will introduce the very basics of using TensorFlow on Alvis.\n",
    "\n",
    "As usual with Python the first step will be to load the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the data\n",
    "In this step we generate a very simple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_true(x, slope=0.5, bias=0.3):\n",
    "    '''The true underlying relation.'''\n",
    "    return slope * x + bias\n",
    "\n",
    "def get_data(n_points, noise_level=0.1, true_function=f_true, **tf_kwargs):\n",
    "    '''Generates noisy data from true_function.\n",
    "    Arguments:\n",
    "        n_points (int): Number of datapoints to generate\n",
    "        noise_level (float): Std of gaussian noise to be added\n",
    "        true_function (callable): The noiseless underlying function\n",
    "        **function_kwargs: Optional key-word arguments passed to true_function\n",
    "    '''\n",
    "    x = tf.random.uniform((n_points, 1), minval=-1, maxval=1)\n",
    "    y = true_function(x, **tf_kwargs) + tf.random.normal((n_points, 1), stddev=noise_level)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_data(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data\n",
    "As this is a notebook we can use the fact that we can easily take a look at graphical objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "x_plot = tf.linspace(-1, 1, 20)\n",
    "plt.plot(x_plot, f_true(x_plot), label=\"Noiseless relation\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow 2.0 the two main ways to construct models is either through the Sequential API or the Functional API. The sequential API catches the most common use cases were all of the layers in your deep learning are handled sequentially, the functional API on the other hand can handle computational graphs that are a lot more complex.\n",
    "\n",
    "In this example we will use the functional API even if the Sequential API would have been sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(1,))\n",
    "linear = layers.Dense(1)\n",
    "outputs = linear(inputs)\n",
    "\n",
    "# Instantiate the model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"linear_model\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this simple case, we could have simply done\n",
    "```python\n",
    "model = keras.Sequential(layers.Dense(1, input_shape=(1,)))\n",
    "```\n",
    "directly, but we will build on this simple model later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Here we will use gradient descent to train our regression model on the data we have generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.1, momentum=0.3),\n",
    ")\n",
    "\n",
    "history = model.fit(x, y, epochs=20, batch_size=x.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "Here we generate new data that we can use to evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(*get_data(100))\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, if you are doing computations with tensors that you do not want to update during training you can use\n",
    "```python\n",
    "out_tensor = torch.stop_gradient(my_func(in_tensor))\n",
    "```\n",
    "or simply specify that they do not require gradients directly\n",
    "```python\n",
    "# For specific tensor\n",
    "my_constant = tf.constant(value)\n",
    "```\n",
    "\n",
    "Compared to PyTorch `model(inputs)` does not by default compute the gradients as the backpropagation is handled by the fit method. If you want to handle this yourself you can check out [tensorflow.GradientTape](https://www.tensorflow.org/guide/autodiff)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "x_plot = tf.linspace(-1, 1, 20)\n",
    "plt.plot(x_plot, f_true(x_plot), label=\"Noiseless relation\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "# Add model prediction\n",
    "plt.plot(x_plot, model.predict(x_plot), label=\"Predicted relation\")\n",
    "\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your own model\n",
    "In TensorFlow 2 most use cases can be handled by the [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) or [Functional API](https://www.tensorflow.org/guide/keras/functional). This can then be extended by writing your own [custom layers](https://www.tensorflow.org/tutorials/customization/custom_layers), [custom losses](https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough) or [custom metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Metric)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercises (optional)\n",
    "1. Implement your own linear regression model with a fixed bias of 0.3, this can be done in several\n",
    "different ways. Depending on your approach you might want to take a look at creating your own custom layer or use go very low level and you can subclass `tf.keras.Model` and use `tf.Variable` and `tf.constant`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "my_model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(model):\n",
    "    if model is None:\n",
    "        raise ValueError(\"Model is None.\")\n",
    "    x, y = get_data(1000)\n",
    "    try:\n",
    "        model(x)\n",
    "    except Exception as e:\n",
    "        print(\"Your model doesn't seem to handle input tensors of shape\", x.size())\n",
    "        raise e\n",
    "\n",
    "    # Check bias\n",
    "    bias_failure = False\n",
    "    def check_bias(model):\n",
    "        model_bias = model(tf.zeros((1, 1)))\n",
    "        try:\n",
    "            tf.debugging.assert_near(model_bias, tf.constant([[0.3]]))\n",
    "        except tf.errors.InvalidArgumentError as e:\n",
    "            nonlocal bias_failure\n",
    "            bias_failure = True\n",
    "            print(model.weights)\n",
    "            print(f\"Failure: The bias is {float(model_bias)}, not 0.3\")\n",
    "    check_bias(model)\n",
    "    \n",
    "    # Check that training changes the model performance\n",
    "    if len(model.weights) != 1:\n",
    "        print(\"Failure: Your model doesn't seem to only have a slope parameter.\")\n",
    "    \n",
    "    # Check bias after training\n",
    "    model_copy = tf.keras.models.clone_model(model)\n",
    "    model_copy.set_weights([(var + 1) * 10 for var in model.weights])\n",
    "\n",
    "    if not bias_failure:\n",
    "        print(\"Checking model bias after changing variable values...\")\n",
    "        check_bias(model_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on a single GPU\n",
    "For this example you will need access to a GPU, on Alvis there are four T4 GPUs\n",
    "available on the login node, to see their status you can use the command\n",
    "`nvidia-smi`. If they seem to be available then you can go ahead and use one of\n",
    "them for the following excercises, otherwise you will have to submit a job.\n",
    "\n",
    "You can use the Alvis OnDemand portal or submit a job manually with sbatch.\n",
    "\n",
    "If you are going to submit a job you can modify the `jobscript-tensorflow.sh`\n",
    "file, if you have forgotten what to think about when constructing a job script\n",
    "you can take a look at part 1 and/or the introduction slides.\n",
    "\n",
    "Now for the actual coding. In TensorFlow GPU acceleration on a single GPU is\n",
    "handled transparently with no code changes, an overview of this you can find\n",
    "in the TF [GPU Guide](https://www.tensorflow.org/guide/gpu).\n",
    "\n",
    "To make sure that your code runs on a GPU you can first check\n",
    "```python\n",
    "tf.config.list_physical_devices('GPU')\n",
    "```\n",
    "and for detailed information on all operations use\n",
    "```python\n",
    "import tensorflow as tf\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "```\n",
    "note that you'll have to do this at the very start of your code.\n",
    "\n",
    "If you want to run on a specific device you can use\n",
    "```\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    # Operations on GPU 0\n",
    "```\n",
    "\n",
    "\n",
    "### Excercises\n",
    "1. Use `nvidia-smi` to find out about current GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decide if you will do the following excercises on the log-in node or if you\n",
    "will submit a job. Or both for the experience\n",
    "3. Modify the below code to see if your training runs on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should modify this block so that it runs on a GPU\n",
    "# and later also change the amount of data to train on\n",
    "\n",
    "x, y = get_data(300)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    layers.Dense(1),\n",
    ")\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.1, momentum=0.3),\n",
    ")\n",
    "\n",
    "model.fit(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. When you think you've succeded submit it with the jobscript.sh\n",
    "5. Redo the GPU training but now do it with 1 billion data points. \n",
    "6. Use `sacct` in a terminal to find the job ID and then run `job_stats.py JOB_ID`\n",
    "after substituting in the job ID. Look at the generated link. Are you using the GPU well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
