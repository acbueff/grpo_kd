{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with PyTorch on Alvis\n",
    "This will introduce the very basics of using PyTorch on Alvis.\n",
    "\n",
    "As usual with Python the first step will be to load the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# For performance set precision,\n",
    "# see https://www.c3se.chalmers.se/documentation/applications/pytorch/#performance-and-precision\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the data\n",
    "In this step we generate a very simple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_true(x, slope=0.5, bias=0.3):\n",
    "    '''The true underlying relation.'''\n",
    "    return slope * x + bias\n",
    "\n",
    "def get_data(n_points, noise_level=0.1, true_function=f_true, **tf_kwargs):\n",
    "    '''Generates noisy data from true_function.\n",
    "    Arguments:\n",
    "        n_points (int): Number of datapoints to generate\n",
    "        noise_level (float): Std of gaussian noise to be added\n",
    "        true_function (callable): The noiseless underlying function\n",
    "        **function_kwargs: Optional key-word arguments passed to true_function\n",
    "    '''\n",
    "    x = 2 * torch.rand(n_points, 1) - 1\n",
    "    y = true_function(x, **tf_kwargs) + noise_level * torch.randn(n_points, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_data(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data\n",
    "As this is a notebook we can use the fact that we can easily take a look at graphical objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "x_plot = torch.linspace(-1, 1, 20)\n",
    "plt.plot(x_plot, f_true(x_plot), label=\"Noiseless relation\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    '''A PyTorch linear regression model.'''\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        # In this function initialize objects that we want to use later\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Here we define the forward pass\n",
    "        # PyTorch will keep track of the computational graph in the background,\n",
    "        # which means we don't have to worry about implementing the backwards pass\n",
    "        return self.linear(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = LinearModel(in_features=1, out_features=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this simple case, we could have simply done\n",
    "```python\n",
    "model = nn.Linear(in_features=1, out_features=1)\n",
    "```\n",
    "directly, but we will build on this simple model later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Here we will use gradient descent to train our regression model on the data we have generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_function, optimizer, n_epochs=20):\n",
    "    '''Training the model.'''\n",
    "    # Notify model to use training settings, used in possible dropout layers etc.\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch + 1:2d}/{n_epochs}\", end=\"\")\n",
    "        \n",
    "        # Reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        loss = loss_function(y_pred, y)\n",
    "        \n",
    "        print(f\"\\tLoss {loss:.4g}\")\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Specify loss function and link optimizer with model parameters\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.3)\n",
    "\n",
    "# Start the training\n",
    "train(model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "Here we generate new data that we can use to evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(x_val, y_val, model, metric):\n",
    "    '''Evaluating the model'''\n",
    "    model.eval()\n",
    "    # We don't need to calculate any gradients\n",
    "    with torch.no_grad():\n",
    "        return metric(model(x_val), y_val)\n",
    "\n",
    "\n",
    "loss = eval(*get_data(100), model, loss_function)\n",
    "print(f\"Test loss: {loss:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, if you are doing computations with tensors that you are not planning\n",
    "to perform backpropagation or differentiation over, then you can detach them from\n",
    "the current graph with\n",
    "```python\n",
    "my_free_tensor = my_tensor.detach()\n",
    "```\n",
    "or simply specify that they do not require gradients directly\n",
    "```python\n",
    "# For specific tensor\n",
    "my_tensor.requires_grad = False\n",
    "\n",
    "# For an entire context\n",
    "with torch.no_grad():\n",
    "    validation_accuracy = (validation_labels == predicted_labels).float().mean()\n",
    "```\n",
    "This will reduce the load of these computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, y, '.', label=\"Data\")\n",
    "x_plot = torch.linspace(-1, 1, 20).unsqueeze(1)\n",
    "plt.plot(x_plot, f_true(x_plot), label=\"Noiseless relation\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "# Add model prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    plt.plot(x_plot, model(x_plot), label=\"Predicted relation\")\n",
    "\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your own model\n",
    "In PyTorch the main way to construct a neural network model is by inheriting\n",
    "from PyTorch\n",
    "[Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module).\n",
    "In many cases it is enough to implement a forward method, this is what you will\n",
    "do now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercises\n",
    "1. (Optional) Modify `MyModel` to be a linear regression model with a fixed bias of 0.3, this can be done in several\n",
    "different ways. Depending on your approach you might want to take a look at the\n",
    "options for the\n",
    "[Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your code here\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        '''Forward method of the module.'''\n",
    "        # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "my_model = MyModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(model):\n",
    "    '''Verify model performance\n",
    "    \n",
    "    This is a help function to see if your model does what it is supposed to do.\n",
    "    '''\n",
    "    x, y = get_data(1000)\n",
    "    try:\n",
    "        model(x)\n",
    "    except Exception as e:\n",
    "        print(\"Your model doesn't seem to handle input tensors of shape\", x.size())\n",
    "        raise e\n",
    "\n",
    "    # Check bias\n",
    "    bias_failure = False\n",
    "    def check_bias(model):\n",
    "        model_bias = model(torch.zeros(1, 1))\n",
    "        if not torch.isclose(model_bias, torch.Tensor([[0.3]])):\n",
    "            nonlocal bias_failure\n",
    "            bias_failure = True\n",
    "            print(f\"Failure: The bias is {model_bias.item()}, not 0.3\")\n",
    "    check_bias(model)\n",
    "    \n",
    "    # Check that training changes the model performance\n",
    "    from copy import deepcopy\n",
    "    model_copy = deepcopy(model)\n",
    "    optimizer = torch.optim.SGD(model_copy.parameters(), lr=10)\n",
    "    out1 = model_copy(x)\n",
    "    nn.MSELoss()(out1, 2 * y).backward()\n",
    "    optimizer.step()\n",
    "    out2 = model_copy(x)\n",
    "    if torch.allclose(out1, out2):\n",
    "        print(\"Failure: The training doesn't seem to affect model performance\")\n",
    "    \n",
    "    # Check bias after training\n",
    "    if not bias_failure:\n",
    "        print(\"Checking model performance after training...\")\n",
    "        check_bias(model_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on a single GPU\n",
    "For this example you will need access to a GPU, on Alvis there are four T4 GPUs\n",
    "available on the login node, to see their status you can use the command\n",
    "`nvidia-smi`. If they seem to be available then you can go ahead and use one of\n",
    "them for the following excercises, otherwise you will have to submit a job.\n",
    "\n",
    "You can use the Alvis OnDemand portal or submit a job manually with sbatch.\n",
    "\n",
    "If you are going to submit a job you can modify the `jobscript.sh` file, if you\n",
    "have forgotten what to think about when constructing a job script you can take a\n",
    "look at part 1 and/or the introduction slides.\n",
    "\n",
    "Now for the actual coding. In PyTorch the way to move computations to the GPU is\n",
    "to move the objects that are part of the computation to the GPU. First create a\n",
    "variable for the device you want to use\n",
    "```python\n",
    "dev = torch.device(\"cuda:0\") \n",
    "```\n",
    "you can change the zero to any other GPU that is available. Note that even if\n",
    "you only have access to a part of a node the GPUs you have access to will still\n",
    "always start from 0.\n",
    "\n",
    "The second step is to move the data and model to the GPU this can be done by\n",
    "calling\n",
    "```pytorch\n",
    "x_gpu = x.to(dev)\n",
    "y_gpu = y.to(dev)\n",
    "model = model.to(dev)\n",
    "```\n",
    "note that you can't use tensors on the GPU to plot with, for these you will have to send them to CPU first.\n",
    "\n",
    "### Excercises\n",
    "1. Use `nvidia-smi` to find out about current GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Decide if you will do the following excercises on the log-in node or if you\n",
    "will submit a job\n",
    "3. Modify `train_gpu()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should modify this block so that it runs on a GPU\n",
    "# and later also change the amount of data to train on\n",
    "\n",
    "x, y = get_data(300)\n",
    "\n",
    "def train_gpu(model, loss_function, optimizer, n_epochs=20):\n",
    "    '''Training the model.'''\n",
    "    # Notify model to use training settings, used in possible dropout layers etc.\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch + 1:2d}/{n_epochs}\", end=\"\")\n",
    "        \n",
    "        # Reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        loss = loss_function(y_pred, y)\n",
    "        \n",
    "        print(f\"\\tLoss {loss:.4g}\")\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Specify loss function and link optimizer with model parameters\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.3)\n",
    "\n",
    "# Start the training\n",
    "train(model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. When you think you've succeded submit it with the jobscript.sh\n",
    "5. Redo the GPU training but now do it with 1 billion data points. Compare the Grafana plots (that is, the page generated by `job_stats.py`)\n",
    "6. Use `sacct` in a terminal to find the job ID and then run `job_stats.py JOB_ID`\n",
    "after substituting in the job ID. Look at the generated link. Are you using the GPU well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
