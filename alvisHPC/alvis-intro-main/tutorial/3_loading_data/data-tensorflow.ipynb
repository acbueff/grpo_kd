{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data with TensorFlow\n",
    "In this notebook we will investigate a few different ways to handle data with TensorFlow on Alvis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your own data\n",
    "In many cases you have a dataset in mind that you've already acquired and are keeping in your home folder or perhaps more probable in a storage project.\n",
    "\n",
    "In this section we will use the `tiny-imagenet-200` that is one of the centrally stored datasets. However, if you've got your own private dataset then the only difference will be that you would store it in your project storage instead.\n",
    "\n",
    "***N.B.:*** We've found that that fastest way to load data on Alvis is to directly stream from archives stored on Mimer. Utilities exist in tensorflow.datasets for zip and tar, but you could just as well and probably more easily use built-in zipfile and tarfile libraries in combination with [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) as done here. Loading from tfrecords might work just as well if not better.\n",
    "\n",
    "### The file tree\n",
    "First we inspect the dataset archive that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "path_to_dataset = '/mimer/NOBACKUP/Datasets/tiny-imagenet-200/tiny-imagenet-200.zip'\n",
    "with zipfile.ZipFile(path_to_dataset) as archive:\n",
    "    # Print first 10 files\n",
    "    print(*archive.namelist()[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NOTE:*** Investigating files like this can be quite slow if the archives are very large. Looking at the first few files are fast and can be good to get a sense of the file, but you don't want to have to search through them every time. If there is a README in connection with the dataset it is wise to take a look at it. Furthermore, you might want to note down the structure inside the archive yourself if it isn't in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at one of the text files next\n",
    "with zipfile.ZipFile(path_to_dataset) as archive:\n",
    "    wnids = archive.read(\n",
    "        'tiny-imagenet-200/wnids.txt'\n",
    "    ).decode(\n",
    "        'utf-8'\n",
    "    ).split()\n",
    "    print(wnids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will later be used as the labels for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at a few example images\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Construct filter for training images\n",
    "def train_image_filter(filename):\n",
    "    return fnmatch(filename)\n",
    "\n",
    "# Construct generator for train images\n",
    "def iter_train_images():\n",
    "    with zipfile.ZipFile(path_to_dataset) as archive:\n",
    "        for fn in archive.namelist():\n",
    "            # Filter for train images\n",
    "            if not fnmatch(fn, '*train*.JPEG'):\n",
    "                continue\n",
    "            \n",
    "            # Decode label from filename\n",
    "            label = fn.split('/')[-1].split('_')[0]\n",
    "            \n",
    "            # Parse image\n",
    "            with archive.open(fn) as imgfile:\n",
    "                img = plt.imread(imgfile)\n",
    "            \n",
    "            yield img, label\n",
    "\n",
    "            \n",
    "# Visualize images\n",
    "fig, ax_grid = plt.subplots(3, 3, figsize=(15, 15))\n",
    "for ax, (img, label) in zip(ax_grid.flatten(), iter_train_images()):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f'Label {label}')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Dataset\n",
    "Now we have an idea of the structure of the dataset and are ready to write our Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# Write a generator for the dataset\n",
    "def dataset_generator(\n",
    "    path=path_to_dataset,\n",
    "    split='train',\n",
    "    shuffle=True,\n",
    "):\n",
    "    with zipfile.ZipFile(path) as archive:\n",
    "        # Find wnid too label mapping\n",
    "        wnids = archive.read(\n",
    "            'tiny-imagenet-200/wnids.txt'\n",
    "        ).decode(\n",
    "            'utf-8'\n",
    "        ).split()\n",
    "        wnid2label = {wnid: [label] for label, wnid in enumerate(wnids)}\n",
    "        \n",
    "        # Iterate over images\n",
    "        namelist = archive.namelist()\n",
    "        if shuffle:\n",
    "            random.shuffle(namelist)\n",
    "        \n",
    "        for filename in namelist:\n",
    "            # Filter for JPEG files and split\n",
    "            if not fnmatch(filename, f'*{split}*.JPEG'):\n",
    "                continue\n",
    "            \n",
    "            # Read label\n",
    "            if split != 'train':\n",
    "                raise NotImplementedError('Reading label only implemented for train split.')\n",
    "            wnid = filename.split('/')[-1].split('_')[0]\n",
    "            label = wnid2label[wnid]\n",
    "            \n",
    "            # Read image\n",
    "            with archive.open(filename) as imgfile:\n",
    "                img = plt.imread(imgfile)\n",
    "            if img.ndim == 2:\n",
    "                # Not all images in tiny-imagenet are RGB valued\n",
    "                img = img[..., None]\n",
    "                img = tf.image.grayscale_to_rgb(\n",
    "                    tf.convert_to_tensor(\n",
    "                        img,\n",
    "                        dtype=tf.float32,\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            yield img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get size of train split\n",
    "with zipfile.ZipFile(path_to_dataset) as archive:\n",
    "    n_train = len([fn for fn in archive.namelist() if fnmatch(fn, '*train*.JPEG')])\n",
    "print(\"Train split is\", n_train, \"images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset object\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=dataset_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(64, 64, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(1), dtype=tf.int32),\n",
    "    ),\n",
    ")\n",
    "\n",
    "n_epochs = 3\n",
    "dataset = dataset.repeat(n_epochs)\n",
    "batch_size = 128\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE);\n",
    "# See https://www.tensorflow.org/guide/data_performance\n",
    "# for more performance considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have a dataset with the structure \"root/class/input\" then we can use `tf.keras.utils.image_dataset_from_directory`. But we want to avoid working with many small files for perfomance reasons, so we wrote our own iterator over an archive instead. A similar approach can be used for tarfiles, but that approach will not be as fast if we want to shuffle the data. HDF5 and TFRecord based approaches should work just as well, but will use some different tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier from this data\n",
    "Now we have some understanding of what the database does and we are ready to do some ML on it.\n",
    "\n",
    "First we will define our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 (3, 3) convolutional filters followed by a dense layer\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(10, 3, activation=\"relu\", input_shape=(64, 64, 3), use_bias=True),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(200),\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    keras.optimizers.Adam(learning_rate=0.01),\n",
    "    keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy', 'top_k_categorical_accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    dataset,\n",
    "    steps_per_epoch=(n_train // batch_size),\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might notice the accuracy is not very good with this very simple model and no hyperparameter tuning. But that's not the topic for this excercise so let's ignore that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Tasks\n",
    " 1. Make yourself acquainted with the above code.\n",
    " 2. (Optional) play around with hyperparameters to get data loading to be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using available datasets\n",
    "Some common public datasets are available at `/mimer/NOBACKUP/Datasets`, if there are some specific dataset you would like to see added you can create a request at [NAISS-support](https://supr.naiss.se/support/).\n",
    "\n",
    "In this part we will access the MNIST dataset available at `/mimer/NOBACKUP/Datasets/MNIST/mnist.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 (3, 3) convolutional filters followed by a dense layer\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(10, 3, activation=\"relu\", input_shape=(28, 28, 1), use_bias=True),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we'll load the data has numpy arrays through the TensorFlow Keras backend. Then we'll massage this output into the correct shape. Another alternative would have been to use the TensorFlow Datasets API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_imgs, train_labels), _ = keras.datasets.mnist.load_data(path=\"/mimer/NOBACKUP/Datasets/MNIST/mnist.npz\")\n",
    "train_data = (\n",
    "    tf.expand_dims(train_imgs, 3),\n",
    "    tf.one_hot(train_labels, 10),\n",
    ")\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_data).batch(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    keras.optimizers.Adam(learning_rate=0.01),\n",
    "    keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(dataset, steps_per_epoch=len(dataset), epochs=3, verbose=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data through a TensorFlow related API\n",
    "Some datasets can be found and used through TensorFlow Keras as we did in the earlier example. The only difference is to change the path to were you would like to store the dataset. More datasets can be found through the [TensorFlow Datasets](https://www.tensorflow.org/datasets/overview), this package doesn't currently exist in the module tree but if interest exist it can probably be added.\n",
    "\n",
    "However, note that for both of these the data download can take some time and you will have to store them yourself. So for your and others sake please see if the datasets exist and for larger datasets don't hesitate to contact support if your are hesitant about anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
